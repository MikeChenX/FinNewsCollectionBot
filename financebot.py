# ç¦ç”Ÿæ— é‡å¤©å°Š
from openai import OpenAI
import feedparser
import requests
from newspaper import Article
from datetime import datetime
import time
import pytz
import os
from typing import Dict, Tuple, List

# OpenAI API Key
openai_api_key = os.getenv("OPENAI_API_KEY")
# ä»ç¯å¢ƒå˜é‡è·å– Serveré…± SendKeys
server_chan_keys_env = os.getenv("SERVER_CHAN_KEYS")
if not server_chan_keys_env:
    raise ValueError("ç¯å¢ƒå˜é‡ SERVER_CHAN_KEYS æœªè®¾ç½®ï¼Œè¯·åœ¨Github Actionsä¸­è®¾ç½®æ­¤å˜é‡ï¼")
server_chan_keys = server_chan_keys_env.split(",")

openai_client = OpenAI(api_key=openai_api_key, base_url="https://api.deepseek.com/v1")

# æ‰©å±•RSSæºï¼šæ–°å¢æ°‘ç”Ÿ/ç»¼åˆçƒ­ç‚¹æºï¼Œé€‚é…æ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆ
rss_feeds = {
    "ğŸ”¥ æ¯æ—¥ç»¼åˆçƒ­ç‚¹": {
        "å¤®è§†æ–°é—»":"https://news.cctv.com/rss/news.shtml",
        "äººæ°‘æ—¥æŠ¥":"https://www.people.com.cn/rss/201905/17/c1008-40359834.html",
        "æ–°åç¤¾":"http://www.xinhuanet.com/rss.xml"
    },
    "ğŸ’² è´¢ç»çƒ­ç‚¹":{
        "åå°”è¡—è§é—»":"https://dedicated.wallstreetcn.com/rss.xml",
        "ä¸œæ–¹è´¢å¯Œ":"http://rss.eastmoney.com/rss_partener.xml",
    },
    "ğŸ  æ°‘ç”Ÿæ”¿ç­–": {
        "ä¸­å›½æ”¿åºœç½‘":"http://www.gov.cn/fuwu/bmfw/rss.htm",
        "ä¸­æ–°ç½‘æ°‘ç”Ÿ":"https://www.chinanews.com.cn/rss/minsheng.xml",
    }
}

# è·å–åŒ—äº¬æ—¶é—´
def today_date():
    return datetime.now(pytz.timezone("Asia/Shanghai")).date()

# çˆ¬å–ç½‘é¡µæ­£æ–‡ (ç”¨äº AI åˆ†æï¼Œä½†ä¸å±•ç¤º)
def fetch_article_text(url):
    try:
        print(f"ğŸ“° æ­£åœ¨çˆ¬å–æ–‡ç« å†…å®¹: {url}")
        article = Article(url)
        article.download()
        article.parse()
        text = article.text[:800]  # çƒ­ç‚¹é€Ÿè§ˆåªéœ€æ ¸å¿ƒä¿¡æ¯ï¼Œç¼©çŸ­æ–‡æœ¬é•¿åº¦
        if not text:
            print(f"âš ï¸ æ–‡ç« å†…å®¹ä¸ºç©º: {url}")
        return text
    except Exception as e:
        print(f"âŒ æ–‡ç« çˆ¬å–å¤±è´¥: {url}ï¼Œé”™è¯¯: {e}")
        return "ï¼ˆæœªèƒ½è·å–æ–‡ç« æ­£æ–‡ï¼‰"

# æ·»åŠ  User-Agent å¤´
def fetch_feed_with_headers(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    return feedparser.parse(url, request_headers=headers)

# è‡ªåŠ¨é‡è¯•è·å– RSS
def fetch_feed_with_retry(url, retries=3, delay=5):
    for i in range(retries):
        try:
            feed = fetch_feed_with_headers(url)
            if feed and hasattr(feed, 'entries') and len(feed.entries) > 0:
                return feed
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {i+1} æ¬¡è¯·æ±‚ {url} å¤±è´¥: {e}")
            time.sleep(delay)
    print(f"âŒ è·³è¿‡ {url}, å°è¯• {retries} æ¬¡åä»å¤±è´¥ã€‚")
    return None

# è·å–RSSå†…å®¹ï¼ˆçˆ¬å–æ­£æ–‡ä½†ä¸å±•ç¤ºï¼‰
def fetch_rss_articles(rss_feeds, max_articles=10) -> Tuple[Dict[str, str], str]:
    news_data = {}
    analysis_text = ""  # ç”¨äºAIåˆ†æçš„æ­£æ–‡å†…å®¹

    for category, sources in rss_feeds.items():
        category_content = ""
        for source, url in sources.items():
            print(f"ğŸ“¡ æ­£åœ¨è·å– {source} çš„ RSS æº: {url}")
            feed = fetch_feed_with_retry(url)
            if not feed:
                print(f"âš ï¸ æ— æ³•è·å– {source} çš„ RSS æ•°æ®")
                continue
            print(f"âœ… {source} RSS è·å–æˆåŠŸï¼Œå…± {len(feed.entries)} æ¡æ–°é—»")

            articles = []  # æ¯ä¸ªsourceéƒ½éœ€è¦é‡æ–°åˆå§‹åŒ–åˆ—è¡¨
            for entry in feed.entries[:5]:
                title = entry.get('title', 'æ— æ ‡é¢˜')
                link = entry.get('link', '') or entry.get('guid', '')
                if not link:
                    print(f"âš ï¸ {source} çš„æ–°é—» '{title}' æ²¡æœ‰é“¾æ¥ï¼Œè·³è¿‡")
                    continue

                # çˆ¬å–æ­£æ–‡ç”¨äºåˆ†æï¼ˆä¸å±•ç¤ºï¼‰
                article_text = fetch_article_text(link)
                analysis_text += f"ã€{title}ã€‘\n{article_text}\n\n"

                print(f"ğŸ”¹ {source} - {title} è·å–æˆåŠŸ")
                articles.append(f"- [{title}]({link})")

            if articles:
                category_content += f"### {source}\n" + "\n".join(articles) + "\n\n"

        news_data[category] = category_content

    return news_data, analysis_text

# ä¼˜åŒ–ï¼šåˆè§„æ ¡éªŒå‡½æ•°ï¼ˆé€‚é…æ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆï¼‰
def compliance_check(content: str) -> Tuple[bool, str]:
    """
    æ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆå†…å®¹åˆè§„æ ¡éªŒï¼ˆé€‚é…æŠ–éŸ³ç›‘ç®¡è¦æ±‚ï¼‰
    """
    # ç¦æ­¢å…³é”®è¯ï¼šæ—¶æ”¿æ•æ„Ÿ/å¼•å¯¼æ€§/è¿è§„è¯æ±‡
    forbidden_keywords = [
        "ä¸ªè‚¡æ¶¨åœ", "é¾™å¤´ä¸ªè‚¡", "æ¨è", "ä¹°å…¥", "å–å‡º", "å¿…æ¶¨", "å¿…è·Œ",
        "ç²¾å‡†é¢„æµ‹", "ç¨³èµš", "æŠ„åº•", "é€ƒé¡¶", "æ•æ„Ÿæ—¶æ”¿å…³é”®è¯", "ç…½åŠ¨æ€§è¡¨è¿°",
        "ç»å¯¹åŒ–è¡¨è¿°", "è™šå‡æ‰¿è¯º"
    ]
    
    # æ£€æŸ¥ç¦æ­¢å…³é”®è¯
    found_keywords = [kw for kw in forbidden_keywords if kw in content]
    if found_keywords:
        return False, f"å­˜åœ¨è¿è§„å…³é”®è¯ï¼š{','.join(found_keywords)}ï¼Œè¯·åˆ é™¤æˆ–ä¿®æ”¹ã€‚"
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆè§„å£°æ˜
    if "æœ¬å†…å®¹ä»…ä¸ºä¿¡æ¯æ•´ç†ï¼Œä¸æ„æˆä»»ä½•å»ºè®®" not in content:
        return False, "ç¼ºå°‘åˆè§„å£°æ˜ï¼Œéœ€æ·»åŠ 'æœ¬å†…å®¹ä»…ä¸ºä¿¡æ¯æ•´ç†ï¼Œä¸æ„æˆä»»ä½•å»ºè®®'ã€‚"
    
    return True, "å†…å®¹åˆè§„"

# æ ¸å¿ƒä¿®æ”¹ï¼šç”Ÿæˆæ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆæ‘˜è¦ï¼ˆé€‚é…30-60ç§’å£æ’­+æ–‡å­—é—ªçƒï¼‰
def summarize(text: str) -> str:
    completion = openai_client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": """
             ä½ æ˜¯ä¸“ä¸šçš„æ–°é—»é€Ÿè§ˆç¼–è¾‘ï¼Œéœ€ç”Ÿæˆé€‚é…æŠ–éŸ³30-60ç§’å£æ’­çš„æ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆå†…å®¹ï¼Œè¦æ±‚ï¼š
             1. ç²¾é€‰3-5æ¡å½“æ—¥æ ¸å¿ƒçƒ­ç‚¹ï¼ˆä¼˜å…ˆæ°‘ç”Ÿ/è´¢ç»/æ”¿ç­–ç±»ï¼Œé¿å¼€æ•æ„Ÿæ—¶æ”¿ï¼‰ï¼›
             2. æ¯æ¡çƒ­ç‚¹æ§åˆ¶åœ¨1-2å¥è¯ï¼Œè¯­è¨€é€šä¿—å£è¯­åŒ–ï¼Œé€‚é…å£æ’­èŠ‚å¥ï¼›
             3. ä¸ºæ¯æ¡çƒ­ç‚¹æ ‡æ³¨ã€é—ªçƒå…³é”®è¯ã€‘ï¼ˆ3-5å­—ï¼Œç”¨äºè§†é¢‘æ–‡å­—é—ªçƒï¼‰ï¼›
             4. æ•´ä½“ç»“æ„ï¼šå¼€åœºè¯­+3-5æ¡çƒ­ç‚¹+åˆè§„å£°æ˜ï¼›
             5. æ€»å­—æ•°æ§åˆ¶åœ¨200å­—ä»¥å†…ï¼Œé¿å…ä¸“ä¸šæœ¯è¯­ï¼Œæ— ç»å¯¹åŒ–è¡¨è¿°ï¼›
             6. åˆè§„å£°æ˜å¿…é¡»åŒ…å«ï¼šæœ¬å†…å®¹ä»…ä¸ºä¿¡æ¯æ•´ç†ï¼Œä¸æ„æˆä»»ä½•å»ºè®®ã€‚
             ç¤ºä¾‹æ ¼å¼ï¼š
             å¤§å®¶å¥½ï¼ä»Šå¤©çš„çƒ­ç‚¹é€Ÿè§ˆæ¥äº†ğŸ‘‡
             1. åŒ»ä¿æ–°æ”¿è½åœ°ã€é—¨è¯ŠæŠ¥é”€æè‡³60%ã€‘ï¼šå…¨å›½é—¨è¯ŠæŠ¥é”€æ¯”ä¾‹ç»Ÿä¸€æé«˜è‡³60%ï¼Œè¦†ç›–æ‰€æœ‰å‚ä¿äººç¾¤ã€‚
             2. äººæ°‘å¸å‡å€¼ç ´7.0ã€é€ çº¸æ¿å—å—ç›Šã€‘ï¼šç¦»å²¸äººæ°‘å¸å…‘ç¾å…ƒå‡ç ´7.0ï¼Œé€ çº¸è¡Œä¸šåŸææ–™æˆæœ¬é™ä½ã€‚
             æœ¬å†…å®¹ä»…ä¸ºä¿¡æ¯æ•´ç†ï¼Œä¸æ„æˆä»»ä½•å»ºè®®ã€‚
             """},
            {"role": "user", "content": text}
        ]
    )
    return completion.choices[0].message.content.strip()

# æ ¸å¿ƒä¿®æ”¹ï¼šç”Ÿæˆæ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆè„šæœ¬ï¼ˆé€‚é…æ–‡å­—é—ªçƒè§†é¢‘ï¼‰
def generate_hotspot_scripts(summary: str) -> List[str]:
    """
    ç”Ÿæˆæ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆçš„æŠ–éŸ³æ–‡å­—é—ªçƒè§†é¢‘è„šæœ¬
    è¾“å‡ºï¼šå®Œæ•´å£æ’­è„šæœ¬+æ–‡å­—é—ªçƒæ ‡æ³¨
    """
    # æ‹†åˆ†çƒ­ç‚¹å†…å®¹
    lines = [line.strip() for line in summary.split("\n") if line.strip()]
    
    # æå–å¼€åœºã€çƒ­ç‚¹ã€å£°æ˜
    opening = ""
    hotspots = []
    declaration = ""
    for line in lines:
        if "å¤§å®¶å¥½" in line or "ä»Šå¤©çš„çƒ­ç‚¹" in line:
            opening = line
        elif line.startswith("1.") or line.startswith("2.") or line.startswith("3.") or line.startswith("4.") or line.startswith("5."):
            hotspots.append(line)
        elif "æœ¬å†…å®¹ä»…ä¸ºä¿¡æ¯æ•´ç†" in line:
            declaration = line
    
    # ç”Ÿæˆå®Œæ•´è„šæœ¬
    script = f"""ã€æ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆ-æŠ–éŸ³å£æ’­è„šæœ¬ï¼ˆ30-60ç§’ï¼‰ã€‘
â–¶ï¸ å£æ’­å¼€åœºï¼š{opening}
â–¶ï¸ å£æ’­å†…å®¹ï¼š
"""
    flash_keywords = []  # æå–æ‰€æœ‰é—ªçƒå…³é”®è¯
    for idx, hotspot in enumerate(hotspots):
        # æå–é—ªçƒå…³é”®è¯ï¼ˆã€ã€‘å†…çš„å†…å®¹ï¼‰
        if "ã€" in hotspot and "ã€‘" in hotspot:
            keyword = hotspot.split("ã€")[1].split("ã€‘")[0]
            flash_keywords.append(keyword)
            # ç§»é™¤å…³é”®è¯æ ‡è®°ï¼Œä¿ç•™å£æ’­å†…å®¹
            broadcast_content = hotspot.replace(f"ã€{keyword}ã€‘", "").strip()
            script += f"  {idx+1}. {broadcast_content}\n"
        else:
            script += f"  {idx+1}. {hotspot}\n"
    
    script += f"""â–¶ï¸ å£æ’­ç»“å°¾ï¼š{declaration}

ğŸ¯ æ–‡å­—é—ªçƒæ ‡æ³¨ï¼ˆé€‚é…è§†é¢‘åˆ¶ä½œï¼‰ï¼š
"""
    for idx, keyword in enumerate(flash_keywords):
        script += f"  ç¬¬{idx+1}æ¡çƒ­ç‚¹é—ªçƒè¯ï¼š{keyword}ï¼ˆé—ªçƒé¢‘ç‡0.5ç§’/æ¬¡ï¼Œé«˜å¯¹æ¯”åº¦æ˜¾ç¤ºï¼‰\n"
    
    # è§†é¢‘åˆ¶ä½œå¤‡æ³¨
    script += """
ğŸ“Œ è§†é¢‘åˆ¶ä½œæ³¨æ„ï¼š
1. èƒŒæ™¯ï¼šç®€çº¦çº¯è‰²èƒŒæ™¯ï¼ˆé»‘/ç™½ï¼‰ï¼Œé¿å…å¹²æ‰°ï¼›
2. å­—ä½“ï¼šç™½è‰²å­—ä½“+é»‘è‰²æè¾¹ï¼Œå­—å·24-30å·ï¼›
3. èŠ‚å¥ï¼šå£æ’­è¯´å®Œ1æ¡çƒ­ç‚¹ï¼Œå¯¹åº”å…³é”®è¯é—ªçƒ2æ¬¡ï¼›
4. æ—¶é•¿ï¼šæ•´ä½“æ§åˆ¶åœ¨30-60ç§’ï¼Œè¯­é€Ÿ180-200å­—/åˆ†é’Ÿã€‚
"""
    return [script]

# å‘é€å¾®ä¿¡æ¨é€
def send_to_wechat(title, content):
    for key in server_chan_keys:
        url = f"https://sctapi.ftqq.com/{key}.send"
        data = {"title": title, "desp": content}
        response = requests.post(url, data=data, timeout=10)
        if response.ok:
            print(f"âœ… æ¨é€æˆåŠŸ: {key}")
        else:
            print(f"âŒ æ¨é€å¤±è´¥: {key}, å“åº”ï¼š{response.text}")

# ä¸»æµç¨‹
def main():
    today_str = today_date().strftime("%Y-%m-%d")

    # è·å–RSSæ–°é—»æ•°æ®
    articles_data, analysis_text = fetch_rss_articles(rss_feeds, max_articles=5)
    
    # ç”Ÿæˆæ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆæ‘˜è¦
    hotspot_summary = summarize(analysis_text)
    print(f"\nğŸ“ ç”Ÿæˆæ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆæ‘˜è¦ï¼š\n{hotspot_summary}")
    
    # åˆè§„æ ¡éªŒ
    is_compliant, compliance_result = compliance_check(hotspot_summary)
    if not is_compliant:
        print(f"âŒ å†…å®¹ä¸åˆè§„ï¼š{compliance_result}")
        return
    print("âœ… å†…å®¹åˆè§„æ ¡éªŒé€šè¿‡")
    
    # ç”ŸæˆæŠ–éŸ³æ–‡å­—é—ªçƒè„šæœ¬
    douyin_scripts = generate_hotspot_scripts(hotspot_summary)
    print(f"\nğŸ¬ ç”ŸæˆæŠ–éŸ³è§†é¢‘è„šæœ¬ï¼š")
    for script in douyin_scripts:
        print(script + "\n")
    
    # ç”Ÿæˆæœ€ç»ˆæ¨é€å†…å®¹
    final_summary = f"ğŸ“… **{today_str} æ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆï¼ˆæŠ–éŸ³é€‚é…ç‰ˆï¼‰**\n\n"
    final_summary += "ğŸ“ æ ¸å¿ƒæ‘˜è¦ï¼š\n" + hotspot_summary + "\n\n"
    final_summary += "ğŸ¬ æŠ–éŸ³æ–‡å­—é—ªçƒè„šæœ¬ï¼š\n" + "\n\n".join(douyin_scripts) + "\n\n"
    
    # è¡¥å……æ–°é—»æ¥æº
    final_summary += "---\nğŸ“¡ æ–°é—»æ¥æºï¼š\n"
    for category, content in articles_data.items():
        if content.strip():
            final_summary += f"## {category}\n{content}\n\n"

    # æ¨é€åˆ°å¾®ä¿¡
    send_to_wechat(title=f"ğŸ“Œ {today_str} æ¯æ—¥çƒ­ç‚¹é€Ÿè§ˆï¼ˆæŠ–éŸ³è„šæœ¬ï¼‰", content=final_summary)

if __name__ == "__main__":
    main()